{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91e1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e8c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.W = nn.Embedding(vocab_size, embedding_size) # 모든 단어를 embedding_size 크기로 임베딩\n",
    "        self.Weight = nn.Linear(self.num_filters_total, num_classes, bias=False)\n",
    "        self.Bias = nn.Parameter(torch.ones([num_classes]))\n",
    "        self.filter_list = nn.ModuleList([nn.Conv2d(1, num_filters, (size, embedding_size)) for size in filter_sizes])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X: sentences의 각 문장 별로 각 단어를 index로 바꾼 tensor (batch_size, sequence_length)\n",
    "        embedded_chars = self.W(X) # X의 모든 index를 embedding vector로 바꿈 (batch_size, sequence_length, embedding_size)\n",
    "        embedded_chars = embedded_chars.unsqueeze(dim=1) # (batch_size, 1, sequence_length, embedding_size) # 차원이 1인 차원을 추가\n",
    "        \n",
    "        pooled_outputs = []\n",
    "        for idx, conv in enumerate(self.filter_list):\n",
    "            h = F.relu(conv(embedded_chars))\n",
    "            mp = nn.MaxPool2d((sequence_length - filter_sizes[idx] + 1, 1))\n",
    "            pooled = mp(h).permute(0, 3, 2, 1)\n",
    "            pooled_outputs.append(pooled)\n",
    "        \n",
    "        h_pool = torch.cat(pooled_outputs, len(filter_sizes))\n",
    "        h_pool_flat = torch.reshape(h_pool, [-1, self.num_filters_total])\n",
    "        model = self.Weight(h_pool_flat) + self.Bias\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "261e5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 2\n",
    "sequence_length = 3\n",
    "num_classes = 2\n",
    "filter_sizes = [2, 2, 2]\n",
    "num_filters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99b7feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장의 단어 수는 3 (= sequence_length)\n",
    "sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \\\n",
    "             \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
    "labels = [1, 1, 1, 0, 0, 0] # 1: good, 0: bad\n",
    "\n",
    "batch_size = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d5bda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list)) # 중복 단어 제거\n",
    "word_dict = {word: idx for idx, word in enumerate(word_list)}\n",
    "\n",
    "vocab_size = len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff9b2235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'she': 0,\n",
       " 'that': 1,\n",
       " 'for': 2,\n",
       " 'he': 3,\n",
       " 'i': 4,\n",
       " 'you': 5,\n",
       " 'me': 6,\n",
       " 'sorry': 7,\n",
       " 'awful': 8,\n",
       " 'this': 9,\n",
       " 'baseball': 10,\n",
       " 'loves': 11,\n",
       " 'likes': 12,\n",
       " 'hate': 13,\n",
       " 'is': 14,\n",
       " 'love': 15}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86ef171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4cec152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장 별로 단어들의 index를 가져옴\n",
    "inputs = [ [word_dict[word] for word in sentence.split()] for sentence in sentences ]\n",
    "inputs = torch.LongTensor(inputs) # List -> Tensor\n",
    "\n",
    "targets = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e383ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000  loss: 0.001323\n",
      "Epoch: 2000  loss: 0.000246\n",
      "Epoch: 3000  loss: 0.000088\n",
      "Epoch: 4000  loss: 0.000039\n",
      "Epoch: 5000  loss: 0.000020\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "EPOCHS = 5000\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputs)\n",
    "    \n",
    "    loss = criterion(output, targets)\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoch: {:04d}  loss: {:.6f}'.format(epoch + 1, loss))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69a80f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love is you is Good mean...\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "test_text = \"love is you\"\n",
    "test_inputs = [ [word_dict[word] for word in test_text.split()] ]\n",
    "test_inputs = torch.LongTensor(test_inputs)\n",
    "\n",
    "predict = model(test_inputs).data.max(1, keepdim=True)[1]\n",
    "if predict[0][0] == 0:\n",
    "    print(test_text, \"is Bad mean...\")\n",
    "else:\n",
    "    print(test_text, \"is Good mean...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedba5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b2e3e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 15,  5],\n",
       "        [ 3, 11,  6],\n",
       "        [ 0, 12, 10],\n",
       "        [ 4, 13,  5],\n",
       "        [ 7,  2,  1],\n",
       "        [ 9, 14,  8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8a66474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6104, -0.6037],\n",
       "         [ 1.0356,  0.9875],\n",
       "         [ 0.5431,  0.9982]],\n",
       "\n",
       "        [[-0.7609, -0.9334],\n",
       "         [-1.3904,  1.5549],\n",
       "         [-2.2182, -1.0644]],\n",
       "\n",
       "        [[-0.4611, -2.2616],\n",
       "         [ 1.1070,  0.2645],\n",
       "         [-0.2258, -0.4881]],\n",
       "\n",
       "        [[ 1.6104, -0.6037],\n",
       "         [-0.8689, -0.3644],\n",
       "         [ 0.5431,  0.9982]],\n",
       "\n",
       "        [[-0.9141,  0.4710],\n",
       "         [-1.0834,  1.9768],\n",
       "         [-0.8339,  0.4260]],\n",
       "\n",
       "        [[-1.0548, -1.7132],\n",
       "         [-1.0154, -0.7481],\n",
       "         [-0.7182,  0.9317]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W = nn.Embedding(vocab_size, embedding_size)\n",
    "# W(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
